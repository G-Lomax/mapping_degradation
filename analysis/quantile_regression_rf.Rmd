---
title: "Quantile Regression of Rangeland Productivity - Quantile Regression Forests"
output: html_notebook
author: Guy Lomax
date: 2023-06-19
---

This Notebook conducts quantile regression on rangeland productivity data
using Quantile Regression Forests (QRF), modelling annual gross primary
productivity (GPP) as a function of environmental variables


```{r setup, include = FALSE}

# Data handling
library(tidyverse)
library(sf)
library(here)

# Analysis
library(mlr3verse)
library(mlr3spatiotempcv)
library(ranger)
library(parallel)
library(future)
library(tictoc)
library(beepr)

# Visualisation
library(tmap)
library(mlr3viz)

tmap_options(check.and.fix = TRUE)

# Parallelisation
nc <- detectCores() - 2
options(mc.cores = nc)

```


```{r load, include = FALSE}

countries <- st_read(here("data", "raw", "vector", "natural_earth",
                          "ne_110m_admin_0_countries_fixed.shp"))

ke_tz <- countries %>% filter(NAME %in% c("Kenya", "Tanzania"))

sample_points_raw <- st_read(here("data", "raw", "vector", "coarse",
                                  "coarseScaleSample.geojson"))

twi <- read_csv(here("data", "processed", "csv", "twi_sample.csv"))

ecoregions <- st_read(here("data", "raw", "vector", "coarse", "Ecoregions2017",
                                  "Ecoregions2017.shp"))

rangeland_ecoregions <- filter(ecoregions, ECO_ID %in% c(50, 51, 55, 57)) %>%
  mutate(ECO_NAME = str_replace(ECO_NAME, "Commiphora ", "Commiphora\n"))


```


```{r clean, include = FALSE}

sample_points <- sample_points_raw %>%
  select(-allRangelands, -igbp, -insolation, -meanT) %>%
  mutate(x = st_coordinates(geometry)[,1],
         y = st_coordinates(geometry)[,2]) %>%
  bind_cols(twi) %>%
  rename(twi = hydrosheds_twi_fd8) %>%
  pivot_longer(cols = starts_with(c("GPP","precipitation", "tMean", "parMean")),
               names_to = "index", values_to = "value") %>%
  separate_wider_delim(index, "_", names = c("data", "year")) %>%
  pivot_wider(names_from = data, values_from = value) %>%
  mutate(year = as.numeric(year)) %>%
  filter(GPP > 0) %>%
  st_as_sf(coords = c("x", "y"), crs = 4326)

# Merge tree and shrub fractions into "woody" fraction

sample_points_woody <- sample_points %>%
  mutate(woody = trees + shrubland) %>%
  select(-trees, -shrubland, -grassland)

# Separate precipitation into mean_ppt and ppt_anomaly
sample_points_clean <- sample_points_woody %>%
  group_by(id) %>%
  mutate(mean_ppt = mean(precipitation),
         ppt_anomaly = precipitation / mean_ppt) %>%
  ungroup()

```


# Exploratory data analysis

```{r eda, eval = FALSE}

# Study area map

tm_shape(ke_tz) + tm_borders() +
  tm_shape(rangeland_ecoregions) + tm_fill(col = "ECO_NAME", style = "cat", palette = "Accent") +
  tm_shape(sample_points_raw) + tm_dots(col = "brown")

# Relative fractions of trees, shrubs, grass

ggtern(sample_points) + geom_point(aes(x = grassland, y = shrubland, z = trees), size = 0.1)

sum(sample_points$shrubland > 0.8) / nrow(sample_points)

# GPP-PPT relationship for different fractions of grassland/shrubland

sample_points_woody %>%
  mutate(grass_cat = cut_width(grassland, 0.2, boundary = 0)) %>%
ggplot(aes(x = precipitation, y = GPP)) +
  geom_point(size = 0.2, alpha = 0.2) +
  facet_wrap(~grass_cat) +
  theme_bw() +
  xlim(0, 1200) +
  ylim(0, 6000)

# Histogram of woody cover

sample_points_woody %>%
  group_by(id) %>%
  summarise(map = mean(precipitation),
            woody = mean(woody)) %>%
  ggplot(aes(x = woody)) +
  geom_histogram(fill = "palegreen", colour = "darkgreen", bins = 50) +
  theme_bw()


```
Data preparation for RF modelling

```{r data_prep}

# Create task

cols_to_retain <- c(
  "id",
  "mean_ppt",
  "ppt_anomaly",
  # "elevation",
  "slope",
  "distToRiver",
  "woody",
  "landform",
  "twi",
  "tMean",
  "parMean",
  "sand",
  "slope",
  "year",
  "GPP"
)
sample_points_subset <- sample_points_clean %>%
  filter(!is.na(twi)) %>%
  select(all_of(cols_to_retain))

task_gpp <- as_task_regr_st(
  x = sample_points_subset,
  id = "potential_gpp",
  target = "GPP",
  coords_as_features = FALSE,
  crs = "epsg:4326"
)

task_gpp$set_col_roles("id", roles = "space")
task_gpp$set_col_roles("year", roles = "time")

# Create learner (ranger random forest) with initial tuning values

lrn_ranger <- lrn("regr.ranger", 
                     predict_type = "response",
                     quantreg = TRUE,
                     num.trees = 501,
                     mtry = 3,
                     min.node.size = 50,
                     sample.fraction = 0.6
)

set_threads(lrn_ranger, nc)

# Create resampling strategy

spt_cv_plan <- rsmp("sptcv_cstf", folds = 10)
nspt_cv_plan <- rsmp("cv", folds = 10)



tuner_random <- tnr("random_search")

at_spt <- auto_tuner(
  tuner = tuner_random,
  learner = lrn_ranger_sp,
  resampling = spt_cv_plan,
  measure = tune_msr,
  term_evals = 5
)

at_nsp <- auto_tuner(
  tuner = tuner_random,
  learner = lrn_ranger_nsp,
  resampling = nspt_cv_plan,
  measure = tune_msr,
  term_evals = 5
)


```


Forward feature selection with untuned model to identify key features

```{r rf_fs}

# Create forward feature selection with untuned model, minimising rmse

perf_msr <- msr("regr.rmse")

fs_method <- fs("sequential")

fs_term <- trm("stagnation", iters = 10)

spt_feature_select <- auto_fselector(
  fselector = fs_method,
  learner = lrn_ranger,
  resampling = spt_cv_plan,
  measure = perf_msr,
  terminator = fs_term
)

nspt_feature_select <- auto_fselector(
  fselector = fs_method,
  learner = lrn_ranger,
  resampling = nspt_cv_plan,
  measure = perf_msr,
  terminator = fs_term
)

# Model fitting

tic()
spt_model <- spt_feature_select$train(task_gpp)
toc()
beep(3)

write_rds(spt_model, here("results", "rds", "spt_model_features.rds"))
rm(spt_model)

tic()
nspt_model <- nspt_feature_select$train(task_gpp)
toc()
beep(3)

write_rds(nspt_model, here("results", "rds", "nspt_model_features.rds"))
rm(nspt_model)


```


```{r rf_model, eval = FALSE}

# Clear memory by removing unneeded objects
rm(countries, ke_tz, sample_points_raw, sample_points, sample_points_woody, twi)
gc()

# Spatial model
plan(multisession, workers = nc)

set.seed(123)

tic()
rf_tuned_sp <- progressr::with_progress(
  at_sp$train(task_gpp)
)
toc()
beep(3)

write_rds(rf_tuned_sp, here("results", "rds", "rf_resample_sp.rds"))

rm(rf_tuned_sp)
gc()

# Non-spatial RF model (random CV)
plan(multisession, workers = nc)

set.seed(456)

tic()
rf_resample_nsp <- progressr::with_progress(
  at_nsp$train(task_gpp)
)
toc()
beep(3)

write_rds(rf_resample_nsp, here("results", "rds", "rf_resample_nsp.rds"))

rm(rf_resample_nsp)
gc()


```


Performance assessment of spatial and non-spatial models

```{r performance}

rf_tuned_sp <- read_rds(here("results", "rds", "rf_resample_sp.rds"))
rf_tuned_nsp <- read_rds(here("results", "rds", "rf_resample_nsp.rds"))

# Measures to evaluate model performance
measures <- msrs(c("regr.mae", "regr.rmse", "regr.rsq"))
measures_micro <- msrs(c("regr.mae", "regr.rmse", "regr.rsq"), average = "micro")

rf_predictions_sp <- rf_tuned_sp$predict(task_gpp)
rf_predictions_nsp <- rf_tuned_nsp$predict(task_gpp)

rf_predictions_sp$score(measures)
rf_predictions_nsp$score(measures)

# Plot predicted vs true values

rf_predictions_sp %>%
  ggplot(aes(x = response, y = truth)) +
  geom_point(size = 0.1, alpha = 0.1) +
  geom_abline(intercept = 0, slope = 1, colour = "red") +
  theme_classic() +
  labs(title = "With spatial CV")

rf_predictions_nsp %>%
  ggplot(aes(x = response, y = truth)) +
  geom_point(size = 0.1, alpha = 0.1) +
  geom_abline(intercept = 0, slope = 1, colour = "red") +
  theme_classic() +
  labs(title = "With random CV")

# Predicted quantile values
# rf_predictions_sp_qu <- rf_tuned_sp$predict(data = task_gpp, type = "quantiles", quantiles = 0.9)
# rf_predictions_nsp_qu <- rf_tuned_nsp$predict(task_gpp, type = "quantiles", quantiles = 0.9)

```

Add predictions to task data table and calculate RPI

```{r train}

tsk_data

```





Benchmarking performance across multiple learners 

```{r benchmark_models}

learners <- lrns(c("regr.ranger", "regr.nnet", "regr.svm", "regr.featureless"))

design = benchmark_grid(tsk_gpp, learners, cv10)

head(design)

bmr <- benchmark(design)


```



Predict quantiles for original set

```{r quantiles}

quantile_predictions <- lrn_ranger$predict(type = "quantiles", quantiles = 0.9)

```

